# The Reward Alchemist - Rayv Code-o-Tron 3000 Submission



**Team Name:** Phantom Troupe
**Hackathon:** Rayv Code-o-Tron 3000
**Problem Statement:** #2 - Recommendation Engine to Target Rewards Based on User Persona

## üöÄ Introduction

Welcome to **The Reward Alchemist**! This project tackles the challenge of delivering **hyper-personalized campaign recommendations** tailored to diverse user personas, moving beyond generic targeting to provide suggestions users will genuinely appreciate. We aim to understand users on a deeper level, considering their interests, context, location, and behavior to recommend campaigns (and the rewards they offer) that truly resonate.

This engine was developed for the Rayv Code-o-Tron 3000 hackathon, focusing on **Ingenuity, Execution, Scalability, and Presentation**.

## ‚ú® Key Features & Innovation

*   **üß† Hybrid AI Approach:** Combines the power of **Graph Neural Networks (GraphSAGE)** to capture complex user-campaign relationships and **Sentence Transformers (SBERT)** for deep semantic understanding of text (interests, watch history, campaign promos, categories).
*   **üìç Location-Aware Ranking:** Implements a multi-stage ranking strategy that explicitly prioritizes **local relevance** (Exact Match > Region Match) before refining based on other factors.
*   **üé≠ Dynamic User Tiering:** Addresses the hackathon stretch goal by calculating user tiers ("Basic", "Premium", "Elite") based on simulated user activity and overall GNN model affinity.
*   **üí° Explainable Recommendations:** Provides users with clear, concise reasons ("Why this campaign?") for each recommendation, enhancing transparency and trust.
*   **üáÆüá≥ Culturally Relevant Data Simulation:** Built upon a synthetic dataset specifically designed with realistic "Desi" user personas, interests, and behaviors. *(Dataset provided in `data/` folder)*
*   **üéØ High User Satisfaction (Simulated):** The ranking logic and weighted satisfaction score directly target the core hackathon goal (>80% simulated satisfaction).
*   **‚öôÔ∏è On-Demand Embeddings:** Made a conscious choice for the hackathon environment to compute GNN & SBERT embeddings during prediction to ensure stability and manage memory, trading off speed for reliability in a demo setting.
*   **üñ•Ô∏è Minimalist Dark UI:** A clean, modern, and responsive Flask web interface for an intuitive user experience. Includes loading states for better UX during processing.

## üõ†Ô∏è Technology Stack

*   **Backend:** Python 3.9+, Flask
*   **ML/AI:** PyTorch, PyTorch Geometric (for GNNs), Sentence Transformers (for SBERT), Scikit-learn, Pandas, NumPy
*   **Data Handling:** Joblib (for artifacts), CSV
*   **Frontend:** HTML, CSS (Bootstrap 5 for layout, custom styling), JavaScript (for interactivity & loading states)

## üìÅ Project Structure

*   `app.py`: Flask application, prediction logic
*   `main.py`: Script for data preprocessing & GNN training (Generates artifacts from data in `data/`)
*   `requirements.txt`: Python dependencies
*   `data/`
    *   `Campaigns_Data.csv`: **Provided** input campaign data
    *   `UserProfiles_Data.csv`: **Provided** input user profile data
*   `preprocessed_data_gnn/` *(Generated by `main.py`)*
    *   `recommender_gnn_artifacts_hackathon_final_v2.pkl`: Model weights, encoders, scalers etc.
    *   `campaigns_preprocessed_gnn_hackathon_final_v2.csv`: Processed campaign info for app
    *   `graph_data_hackathon_final_v2.pt`: Saved graph structure & features
*   `templates/`
    *   `index.html`: Main web interface
*   `static/`: (Optional) Folder for static CSS/JS if separated
*   `README.md`: This file

## ‚öôÔ∏è Setup & Installation Guide

**1. Prerequisites:**
    *   Python 3.9 or higher installed.
    *   `pip` (Python package installer).
    *   Git (for cloning).

**2. Clone the Repository:**
    ```bash
    git clone [Your GitHub Repository URL]
    cd [repository-folder-name]
    ```

**3. Create a Virtual Environment (Recommended):**
    ```bash
    python -m venv venv
    # Activate it:
    # Windows:
    .\venv\Scripts\activate
    # macOS/Linux:
    source venv/bin/activate
    ```

**4. Install Dependencies:**
    *   **CRITICAL:** Install PyTorch first, following official instructions for your OS and compute platform (CPU/CUDA): [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)
    *   Then, install PyTorch Geometric and related packages, ensuring compatibility with your PyTorch version: [https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html)
    *   Finally, install the remaining packages:
        ```bash
        pip install -r requirements.txt
        ```
        *(Ensure `requirements.txt` exists and is accurate for your environment.)*

**5. Verify Input Data:**
    *   Ensure the `data` folder exists in the project root.
    *   Confirm that `Campaigns_Data.csv` and `UserProfiles_Data.csv` are present inside the `data` folder. These files are provided in the repository.

## ‚ñ∂Ô∏è Running the Application (Choose ONE Option)

You have two options to run the application:

**Option A: Train Model From Scratch (Requires more time, validates full pipeline)**

This option trains the model using the provided CSV files and generates fresh artifacts.

1.  **Clean Up (Important!):** If the `preprocessed_data_gnn` folder already exists from a previous run, **delete it** completely to ensure a fresh build.
    ```bash
    # Example (use appropriate command for your OS): rm -rf preprocessed_data_gnn
    ```
2.  **Run Training:** Execute the training script (`main.py`). This reads from `data/`, creates `preprocessed_data_gnn/`, and populates it.
    ```bash
    python main.py
    ```
    *(This step can take several minutes to hours depending on data size and hardware.)*
3.  **Run the Flask App:** Once training completes successfully:
    ```bash
    python app.py
    ```
4.  **Access:** Open your web browser to `http://127.0.0.1:5000`.

**Option B: Use Pre-Trained Artifacts (Faster Demo)**

**Option B: Use Pre-Trained Artifacts (Faster Demo)**

Use this option to run the web application directly using pre-generated model artifacts, skipping the potentially long training step.

1.  **Download Artifacts:** Download the required pre-trained artifacts from the following link:
    (https://drive.google.com/drive/folders/1rQwge6fpm50_P9-rfJTVew_jJTV_DPqC?usp=sharing)]
    *(This link points to a folder or ZIP file containing the `preprocessed_data_gnn` directory)*
2.  **Place Artifacts:** Unzip the downloaded file (if applicable) and place the entire `preprocessed_data_gnn` folder directly into the main project directory (the same level as `app.py` and `main.py`). Your structure should look like:
    ```
    YourProjectFolder/
    ‚îú‚îÄ‚îÄ app.py
    ‚îú‚îÄ‚îÄ main.py
    ‚îú‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ preprocessed_data_gnn/  <-- Place the downloaded folder here
    ‚îÇ   ‚îú‚îÄ‚îÄ recommender_gnn_artifacts_hackathon_final_v2.pkl
    ‚îÇ   ‚îú‚îÄ‚îÄ campaigns_preprocessed_gnn_hackathon_final_v2.csv
    ‚îÇ   ‚îî‚îÄ‚îÄ graph_data_hackathon_final_v2.pt
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îî‚îÄ‚îÄ README.md
    ```
3.  **Verify Setup:** Ensure all dependencies are installed (Steps 1-4 from the Setup Guide).
4.  **Run the Flask App Directly:**
    ```bash
    python app.py
    ```
5.  **Access:** Open your web browser to `http://127.0.0.1:5000`.
## deliverables

*   **Source Code:** Contained within this repository, cleaned and commented.
*   **README:** This file.
*   **Video Demo (3-5 mins):** [**<< INSERT LINK TO YOUR VIDEO DEMO HERE >>**]
*   **Write-Up (500 words max):** [**<< INSERT LINK TO YOUR WRITE-UP HERE or state "See SUMMARY.md" >>**]

## üí° Approach Summary

**The Reward Alchemist** employs a hybrid recommendation strategy:

1.  **GNN Embeddings:** GraphSAGE learns rich representations of users and campaigns based on features and interactions during training (using provided data).
2.  **On-Demand Prediction:** For stability, GNN embeddings (for all nodes) and SBERT embeddings (for campaigns) are recalculated *during* each prediction request in the Flask app.
3.  **Multi-Stage Ranking:**
    *   **Location Prioritization:** Exact location matches are ranked highest, followed by regional matches.
    *   **Semantic Sorting:** Within location groups, campaigns are sorted based on SBERT cosine similarity between user's watch history/interests and campaign category/promo text (Watch History match prioritized).
    *   **Explainability:** Simple rules generate a user-friendly reason for each recommendation based on the dominant ranking factors (location, semantic match, GNN score).
4.  **Dynamic Tiering:** User activity level and average GNN relevance score determine a dynamic tier (Basic, Premium, Elite).

This approach balances capturing complex graph patterns with the crucial context of location and semantic meaning, aiming for high user satisfaction.

## üßó Challenges & Learnings

*   **Data Handling:** Working with and preprocessing the provided user/campaign datasets efficiently.
*   **Memory Management:** Balancing the desire for fast predictions (pre-computed embeddings) with memory constraints led to the on-demand embedding strategy for the demo app.
*   **Ranking Logic:** Designing and tuning the multi-stage hybrid ranking required careful consideration of different signals (GNN, SBERT, Location) and their relative importance based on the provided data.
*   **GNN Training:** Finding optimal hyperparameters for GraphSAGE on the provided data required experimentation.

## üöÄ Future Work

*   Integrate real-time user feedback (clicks, skips) for personalization.
*   Incorporate campaign start/end dates for temporal filtering/boosting.
*   Implement a pre-computation pipeline for embeddings in a production setting for scalability.
*   Add result diversification to avoid showing too many campaigns from the same category/brand.


## üë• Team

*   Ishwar
*   Vamshi
*   Nachiketh

---
